sparse autoencoders 
so in this module we will talk about sparse autoencoders 
just some concepts before we jump into the actual way of doing this so hidden neuron 
with sigmoid activation will have values between  zero to one and  you say that the neuron is 
activated when this output is close to one and it is not activated when its output is close to zero 
ok now a spare encoder tries to ensure the neuron is inactive most of the times what is 
that mean 
student close 
it is close to zero for 
student most of the 
most of the 
student 
inputs right so i am passing a lot of inputs to it it will try to ensure that it is close to zero 
for most of the inputs so in other words what does it trying you ensure i am looking 
for  the  word  average  the  average  activation  of  a  neuron  is  close  to  zero  does  that  make 
sense is that fine 
so  this  is  on  what  you  see  on  the  left  hand  side  this  is  how  you  would  compute  the 
average  activation  of  a  given  neuron  you  have  all  the  m  examples  you  see  what  the 
activation was for each of these and take the average right 
now if the neuron is sparse then the average activation would be close to zero is that fine 
this  is  all  just  different  ways  of  saying  the  same  thing  now  a  sparse  encoder  uses  a 
sparsity parameter say rho and it is very close to zero say five 
and it tries to enforce the constraint that on average the activation of any neuron in the 
hidden layer should be equal to rho which is again close to zero now can you think of a 
this is all fine in plain english right you understand what we are trying to do first of all 
tell me why does this makes sense what is it that you are trying to ensure over fitting 
happens because there is lot of dash 
student parameters 
parameters slightly abstract it out 
student memorization 
lot of 
student memorization 
memorization ok lot of freedom right i mean the weights have a lot of freedom to move 
where ever they want to do whatever they want to do such that they can just drive the 
training error to zero what have we done to that freedom now 
student we are restrict 
we  are  restricting  them  so  any  kind  of  regularization  always  tries  to  restrict  this 
freedom that the parameters or the network have in general right and there are different 
ways  of  restricting  this  freedom  you  see  that  this  is  one  of  those  ways  right  you  are 
trying to ensure that on average the neuron should not fire so it is clear that this some 
kind of regularization any one has a doubt with that no 
now the second question is taking slightly more on this right it is i can just move ahead 
and i have convince you that this is regularization but can you think of bit more and see 
what is actually being tried to achieve here what are we trying to do how many of you 
get that or at least could here that first of all only the second row ok so yeah how many 
of you can think about this like what is it trying to achieve 
student 
right so on average neuron is going to be inactive that means where ever it is active it 
is  really  going  to  capture  some  relevant  information  right  so  it  is  going  to  be  active 
whenever  it  is  active  it  is  going  to  adhere  to  certain  patterns  so  we  are  ensuring  that 
each of these neurons are just a very few patterns and it has discriminative power in that 
sense do you get that 
so now if that means if i show it a three if i show it a two if i show it a one every time if the 
neuron fires when there is no discriminative power in that but now if i ensure that the 
neuron fires only a few times it will try to fire for meaning full patterns so it will try to 
fire for a curve or a curve in the between as you have it in the case of three right you have 
this cusp in the between in the middle so it will fire for some kinds of pattern 
so  that  is  what  the  hope  is  it  is  not  just  like  adding  some  math  and  adding  some 
regularization but at least there is some intuition behind that how many of you get that 
intuition  ok  good  and  now  can  tell  me  a  way  of  putting  this  everything  english  is 
fine intuition is fine but how do convert this to a mathematically equation 
you want to ensure that rho hat l is equal to rho there will of course be different ways 
of  doing  this  the  way  these  guys  do  it  by  adding  this  term  to  the  loss  function  so 
remember your loss function is always going to be l dash theta plus omega theta right 
where omega theta does the regularization and l dash theta is  your regular loss which 
would be the squared error loss or the cross entropy loss or whatever loss you are dealing 
with right 
so  remember  this  term  is  always  there  but  the  reason  i  do  not  bring  it  up  so  often  is 
because we have already dealt with it we know how to compute the gradients we know 
how to do the back propagation and all that and now since your final loss is just a sum 
of these two terms i know how to deal with this and i know that gradients are additive so 
i just need to deal with the second term that is why i am only focusing on omega theta 
l theta has been dealt with is that fine 
now this is what omega theta is why does this make sense when would this take its 
minimum value when rho is equal to 
student watt 
watt everyone sees that how many of you sees that please raise your hands ok fine let 
us plot it and check actually right 
so  this  is  how  that  function  looks  like  so  i  have  plotted  the  function  which  i  have 
written here for a of course a single k right and my rho that i have taken is two and if i 
plot that function for different values of rho hat l it will reach the value zero only when rho 
hat l is equal to point so again go back and plot this and check and it is actually clear 
from  the  equations  itself  that  it  will  be  minimized  only  when  rho  hat  is  equal  to  rho  l 
right 
so that means this is a genuine i mean this is a reasonable thing to do we would think 
of other ways of doing that and i am sure  you can but this is also a reasonable way of 
doing this 
so now our last function is as i said it is going to be a combination of two values l theta 
is  a  normal  squared  error  loss  that  we  have  been  dealing  with  and  omega  theta  is  this 
sparsity constraint that you have added 
now you already how to calculate the first term what are we interested in now so you 
see that this pattern will keep repeating right so now you can do whatever you want your 
loss function you have this generic frame of called the back propagation algorithm and 
you know that a last part of that back propagation algorithm is going to remain the same 
right only thing you are changing is the output layer or the loss function 
just need to compute something there and the rest of it will remain the same how many 
of  you  get  this  general  idea  and  also  appreciate  it  right  that  is  why  this  is  a  very 
powerful frame right you can just make minor tweaks at the top and you are rest of the 
code has to remain the same 
so  you  can  actually  go  back  and  try  out  these  regularization  terms  in  mnist 
assignments  right  if  you  really  want  to  see  what  happens  ok  so  now  this  is  what 
omega theta is and now what i am going to do it can be rewritten as this that is obvious 
just expanding out the law of function 
and by chain  rule this is  what  i  get now unfortunately the  rest  of the slide there is  an 
error the ta’s please note this i can kind of overlooked this ah but i will just convey the 
idea right so you would want to do something of this sort everyone agrees with that 
remember what is rho hat it depends on sorry rho hat l it depends on 
student 
h of l right it is the average activation of the l’th neuron and this depends on some of the 
weights so that is why this chain rule makes sense and now how to compute this there 
is an error on this slide but you have done enough gradients in the class for me to have 
confidence that  you can do it on  your own everyone is confident that they can work it 
out on your own 
so  i  will  skip  this  we will  fix  these  errors  there  are  some  summation  and  other  terms 
missing here and the second part is actually correct which has been derived on the next 
slide 
but i would not go over this this is there are the slides again go back and look at it how 
many  of  you  are  confident  that  you  can  do  this  on  your  own  please  raise  your  hands 
yeah because we have done enough of this in class right 
so you can you should be able to it no if you are not able to do it then i am not doing a 
good job at teaching you right so you should be able to do it now fine and we will fix 
these errors so ta’s just remind me after the class so everyone gets the general idea 
you  find  a  loss  you  find  a  constraint  you  define  it  with  omega  theta  find  out  the 
derivative of that with respect to your parameters and just change your gradient descent 
upgrade tool accordingly 
